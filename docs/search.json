[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learningDiary",
    "section": "",
    "text": "About me\nTell you later :)\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#beginning",
    "href": "intro.html#beginning",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.1 Beginning",
    "text": "1.1 Beginning\nBefore starting this course, I need to first understand the purpose of this course, which is to introduce the basic concepts and applications of remote sensing, and through this course of RS, the content we will learn includes:\n\nDefinition, classification and platform of remote perception\nInteraction of electromagnetic waves with the Earth’s surface\nFour resolutions for remote sensing data: spatial, spectral, temporal, and radiative\nFormat, selection, and limitations of remote sensing data\nPractical cases and analysis methods of remote perception data\n\nIt easily reminds me of the basic concepts of RS that I learned by myself during my undergraduate study. I believe that this course can not only help me review the past knowledge, but also fully supplement other knowledge."
  },
  {
    "objectID": "wk2_Portfolio.html",
    "href": "wk2_Portfolio.html",
    "title": "2  Presentation Ninja",
    "section": "",
    "text": "background-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg)\n???\nImage credit: Wikimedia Commons\nclass: inverse, center, middle\n\n3 Get Started\n\n\n\n4 Hello World\nInstall the xaringan package from Github:\n\nremotes::install_github(\"yihui/xaringan\")\n\n–\nYou are recommended to use the RStudio IDE, but you do not have to.\n\nCreate a new R Markdown document from the menu File -&gt; New File -&gt; R Markdown -&gt; From Template -&gt; Ninja Presentation;1\n\n–\n\nClick the Knit button to compile it;\n\n–\n\nor use the RStudio Addin2 “Infinite Moon Reader” to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer.\n\n.footnote[ [1] 中文用户请看这份教程\n[2] See #2 if you do not see the template or addin in RStudio. ]\n\n\n5 Hello Ninja\nAs a presentation ninja, you certainly should not be satisfied by the “Hello World” example. You need to understand more about two things:\n\nThe remark.js library;\nThe xaringan package;\n\nBasically xaringan injected the chakra of R Markdown (minus Pandoc) into remark.js. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (knitr).\n\n\n\n6 remark.js\nYou can see an introduction of remark.js from its homepage. You should read the remark.js Wiki at least once to know how to\n\ncreate a new slide (Markdown syntax* and slide properties);\nformat a slide (e.g. text alignment);\nconfigure the slideshow;\nand use the presentation (keyboard shortcuts).\n\nIt is important to be familiar with remark.js before you can understand the options in xaringan.\n.footnote[[*] It is different with Pandoc’s Markdown! It is limited but should be enough for presentation purposes. Come on… You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js may be improved in the future.]\nclass: inverse, middle, center\n\n\n7 Using xaringan\n\n\n\n8 xaringan\nProvides an R Markdown output format xaringan::moon_reader as a wrapper for remark.js, and you can use it in the YAML metadata, e.g.\n---\ntitle: \"A Cool Presentation\"\noutput:\n  xaringan::moon_reader:\n    yolo: true\n    nature:\n      autoplay: 30000\n---\nSee the help page ?xaringan::moon_reader for all possible options that you can use.\n\n\n\n9 remark.js vs xaringan\nSome differences between using remark.js (left) and using xaringan (right):\n.pull-left[ 1. Start with a boilerplate HTML file;\n\nPlain Markdown;\nWrite JavaScript to autoplay slides;\nManually configure MathJax;\nHighlight code with *;\nEdit Markdown source and refresh browser to see updated slides; ]\n\n.pull-right[ 1. Start with an R Markdown document;\n\nR Markdown (can embed R/other code chunks);\nProvide an option autoplay;\nMathJax just works;*\nHighlight code with {{}};\nThe RStudio addin “Infinite Moon Reader” automatically refreshes slides on changes; ]\n\n.footnote[[*] Not really. See next page.]\n\n\n\n10 Math Expressions\nYou can write LaTeX math expressions inside a pair of dollar signs, e.g. $+$ renders \\(\\alpha+\\beta\\). You can use the display style with double dollar signs:\n$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n\\[\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\\]\nLimitations:\n\nThe source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character;\nThere should not be spaces after the opening $ or before the closing $.\nMath does not work on the title slide (see #61 for a workaround).\n\n\n\n\n11 R Code\n\n# a boring regression\nfit = lm(dist ~ 1 + speed, data = cars)\ncoef(summary(fit))\n\n#               Estimate Std. Error   t value     Pr(&gt;|t|)\n# (Intercept) -17.579095  6.7584402 -2.601058 1.231882e-02\n# speed         3.932409  0.4155128  9.463990 1.489836e-12\n\ndojutsu = c('地爆天星', '天照', '加具土命', '神威', '須佐能乎', '無限月読')\ngrep('天', dojutsu, value = TRUE)\n\n# [1] \"地爆天星\" \"天照\"\n\n\n\n\n\n12 R Plots\n\npar(mar = c(4, 4, 1, .1))\nplot(cars, pch = 19, col = 'darkgray', las = 1)\nabline(fit, lwd = 2)\n\n\n\n\n\n\n\n13 Tables\nIf you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n\nknitr::kable(head(iris), format = 'html')\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\n\n\n\n\n14 HTML Widgets\nI have not thoroughly tested HTML widgets against xaringan. Some may work well, and some may not. It is a little tricky.\nSimilarly, the Shiny mode (runtime: shiny) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications.\nSee the next page for two HTML widgets.\n\n\nlibrary(leaflet)\nleaflet() %&gt;% addTiles() %&gt;% setView(-93.65, 42.0285, zoom = 17)\n\n\n\n\n\n\n\nDT::datatable(\n  head(iris, 10),\n  fillContainer = FALSE, options = list(pageLength = 8)\n)\n\n\n\n\n15 Some Tips\n\nDo not forget to try the yolo option of xaringan::moon_reader.\noutput:\n  xaringan::moon_reader:\n    yolo: true\n\n\n\n\n16 Some Tips\n\nSlides can be automatically played if you set the autoplay option under nature, e.g. go to the next slide every 30 seconds in a lightning talk:\noutput:\n  xaringan::moon_reader:\n    nature:\n      autoplay: 30000\nIf you want to restart the play after it reaches the last slide, you may set the sub-option loop to TRUE, e.g.,\noutput:\n  xaringan::moon_reader:\n    nature:\n      autoplay:\n        interval: 30000\n        loop: true\n\n\n\n\n17 Some Tips\n\nA countdown timer can be added to every page of the slides using the countdown option under nature, e.g. if you want to spend one minute on every page when you give the talk, you can set:\noutput:\n  xaringan::moon_reader:\n    nature:\n      countdown: 60000\nThen you will see a timer counting down from 01:00, to 00:59, 00:58, … When the time is out, the timer will continue but the time turns red.\n\n\n\n\n18 Some Tips\n\nThe title slide is created automatically by xaringan, but it is just another remark.js slide added before your other slides.\nThe title slide is set to class: center, middle, inverse, title-slide by default. You can change the classes applied to the title slide with the titleSlideClass option of nature (title-slide is always applied).\noutput:\n  xaringan::moon_reader:\n    nature:\n      titleSlideClass: [top, left, inverse]\n\n–\n\nIf you’d like to create your own title slide, disable xaringan’s title slide with the seal = FALSE option of moon_reader.\noutput:\n  xaringan::moon_reader:\n    seal: false\n\n\n\n\n19 Some Tips\n\nThere are several ways to build incremental slides. See this presentation for examples.\nThe option highlightLines: true of nature will highlight code lines that start with *, or are wrapped in {{ }}, or have trailing comments #&lt;&lt;;\noutput:\n  xaringan::moon_reader:\n    nature:\n      highlightLines: true\nSee examples on the next page.\n\n\n\n\n20 Some Tips\n.pull-left[ An example using a leading *:\n```r\nif (TRUE) {\n** message(\"Very important!\")\n}\n```\nOutput:\nif (TRUE) {\n* message(\"Very important!\")\n}\nThis is invalid R code, so it is a plain fenced code block that is not executed. ]\n.pull-right[ An example using {{}}:\n```{r tidy=FALSE}\nif (TRUE) {\n*{{ message(\"Very important!\") }}\n}\n```\nOutput:\n\nif (TRUE) {\n{{ message(\"Very important!\") }}\n}\n\nVery important!\n\n\nIt is valid R code so you can run it. Note that {{}} can wrap an R expression of multiple lines. ]\n\n\n\n21 Some Tips\nAn example of using the trailing comment #&lt;&lt; to highlight lines:\n```{r tidy=FALSE}\nlibrary(ggplot2)\nggplot(mtcars) + \n  aes(mpg, disp) + \n  geom_point() +   #&lt;&lt;\n  geom_smooth()    #&lt;&lt;\n```\nOutput:\n\nlibrary(ggplot2)\nggplot(mtcars) + \n  aes(mpg, disp) + \n  geom_point() +   #&lt;&lt;\n  geom_smooth()    #&lt;&lt;\n\n\n\n\n22 Some Tips\nWhen you enable line-highlighting, you can also use the chunk option highlight.output to highlight specific lines of the text output from a code chunk. For example, highlight.output = TRUE means highlighting all lines, and highlight.output = c(1, 3) means highlighting the first and third line.\n```{r, highlight.output=c(1, 3)}\nhead(iris)\n```\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nQuestion: what does highlight.output = c(TRUE, FALSE) mean? (Hint: think about R’s recycling of vectors)\n\n\n\n23 Some Tips\n\nTo make slides work offline, you need to download a copy of remark.js in advance, because xaringan uses the online version by default (see the help page ?xaringan::moon_reader).\nYou can use xaringan::summon_remark() to download the latest or a specified version of remark.js. By default, it is downloaded to libs/remark-latest.min.js.\nThen change the chakra option in YAML to point to this file, e.g.\noutput:\n  xaringan::moon_reader:\n    chakra: libs/remark-latest.min.js\nIf you used Google fonts in slides (the default theme uses Yanone Kaffeesatz, Droid Serif, and Source Code Pro), they won’t work offline unless you download or install them locally. The Heroku app google-webfonts-helper can help you download fonts and generate the necessary CSS.\n\n\n\n\n24 Macros\n\nremark.js allows users to define custom macros (JS functions) that can be applied to Markdown text using the syntax ![:macroName arg1, arg2, ...] or ![:macroName arg1, arg2, ...](this). For example, before remark.js initializes the slides, you can define a macro named scale:\nremark.macros.scale = function (percentage) {\n  var url = this;\n  return '&lt;img src=\"' + url + '\" style=\"width: ' + percentage + '\" /&gt;';\n};\nThen the Markdown text\n![:scale 50%](image.jpg)\nwill be translated to\n&lt;img src=\"image.jpg\" style=\"width: 50%\" /&gt;\n\n\n\n\n25 Macros (continued)\n\nTo insert macros in xaringan slides, you can use the option beforeInit under the option nature, e.g.,\noutput:\n  xaringan::moon_reader:\n    nature:\n      beforeInit: \"macros.js\"\nYou save your remark.js macros in the file macros.js.\nThe beforeInit option can be used to insert arbitrary JS code before remark.create(). Inserting macros is just one of its possible applications.\n\n\n\n\n26 CSS\nAmong all options in xaringan::moon_reader, the most challenging but perhaps also the most rewarding one is css, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know.\nYou can see the default CSS file here. You can completely replace it with your own CSS files, or define new rules to override the default. See the help page ?xaringan::moon_reader for more information.\n\n\n\n27 CSS\nFor example, suppose you want to change the font for code from the default “Source Code Pro” to “Ubuntu Mono”. You can create a CSS file named, say, ubuntu-mono.css:\n@import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n.remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\nThen set the css option in the YAML metadata:\noutput:\n  xaringan::moon_reader:\n    css: [\"default\", \"ubuntu-mono.css\"]\nHere I assume ubuntu-mono.css is under the same directory as your Rmd.\nSee yihui/xaringan#83 for an example of using the Fira Code font, which supports ligatures in program code.\n\n\n\n28 CSS (with Sass)\nxaringan also supports Sass support via rmarkdown. Suppose you want to use the same color for different elements, e.g., first heading and bold text. You can create a .scss file, say mytheme.scss, using the sass syntax with variables:\n$mycolor: #ff0000; \n.remark-slide-content &gt; h1 { color: $mycolor; }\n.remark-slide-content strong { color: $mycolor; }\nThen set the css option in the YAML metadata using this file placed under the same directory as your Rmd:\noutput:\n  xaringan::moon_reader:\n    css: [\"default\", \"mytheme.scss\"]\nThis requires rmarkdown &gt;= 2.8 and the sass package. You can learn more about rmarkdown and sass support in this blog post and in sass overview vignette.\n\n\n\n29 Themes\nDon’t want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files foo.css and foo-fonts.css, where foo is the theme name. Below are some existing themes:\n\nnames(xaringan:::list_css())\n\n [1] \"chocolate-fonts\"  \"chocolate\"        \"default-fonts\"   \n [4] \"default\"          \"duke-blue\"        \"fc-fonts\"        \n [7] \"fc\"               \"glasgow_template\" \"hygge-duke\"      \n[10] \"hygge\"            \"ki-fonts\"         \"ki\"              \n[13] \"kunoichi\"         \"lucy-fonts\"       \"lucy\"            \n[16] \"metropolis-fonts\" \"metropolis\"       \"middlebury-fonts\"\n[19] \"middlebury\"       \"nhsr-fonts\"       \"nhsr\"            \n[22] \"ninjutsu\"         \"rladies-fonts\"    \"rladies\"         \n[25] \"robot-fonts\"      \"robot\"            \"rutgers-fonts\"   \n[28] \"rutgers\"          \"shinobi\"          \"tamu-fonts\"      \n[31] \"tamu\"             \"uio-fonts\"        \"uio\"             \n[34] \"uo-fonts\"         \"uo\"               \"uol-fonts\"       \n[37] \"uol\"              \"useR-fonts\"       \"useR\"            \n[40] \"uwm-fonts\"        \"uwm\"              \"wic-fonts\"       \n[43] \"wic\"             \n\n\n\n\n\n30 Themes\nTo use a theme, you can specify the css option as an array of CSS filenames (without the .css extensions), e.g.,\noutput:\n  xaringan::moon_reader:\n    css: [default, metropolis, metropolis-fonts]\nIf you want to contribute a theme to xaringan, please read this blog post.\nbackground-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg) background-size: 100px background-position: 90% 8%\n\n\n31 Sharingan\nThe R package name xaringan was derived1 from Sharingan, a dōjutsu in the Japanese anime Naruto with two abilities:\n\nthe “Eye of Insight”\nthe “Eye of Hypnotism”\n\nI think a presentation is basically a way to communicate insights to the audience, and a great presentation may even “hypnotize” the audience.2,3\n.footnote[ [1] In Chinese, the pronounciation of X is Sh /ʃ/ (as in shrimp). Now you should have a better idea of how to pronounce my last name Xie.\n[2] By comparison, bad presentations only put the audience to sleep.\n[3] Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations. ]\n\n\n\n32 Naruto terminology\nThe xaringan package borrowed a few terms from Naruto, such as\n\nSharingan (写輪眼; the package name)\nThe moon reader (月読; an attractive R Markdown output format)\nChakra (查克拉; the path to the remark.js library, which is the power to drive the presentation)\nNature transformation (性質変化; transform the chakra by setting different options)\nThe infinite moon reader (無限月読; start a local web server to continuously serve your slides)\nThe summoning technique (download remark.js from the web)\n\nYou can click the links to know more about them if you want. The jutsu “Moon Reader” may seem a little evil, but that does not mean your slides are evil.\n\nclass: center\n\n\n33 Hand seals (印)\nPress h or ? to see the possible ninjutsu you can use in remark.js.\n\n\nclass: center, middle\n\n\n34 Thanks!\nSlides created via the R package xaringan.\nThe chakra comes from remark.js, knitr, and R Markdown."
  },
  {
    "objectID": "wk5_GEE.html#summary",
    "href": "wk5_GEE.html#summary",
    "title": "3  Week5 - Google Earth Engine",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n课程理论部分主要介绍了 GEE 的基本概念、数据结构、操作方法和应用案例。\n\nGEE 的特点：GEE 是一个地理空间处理服务，可以利用云端服务器存储和分析海量的遥感影像和地理数据，实现快速、大规模的地球表面变化监测和模拟。\nGEE 的数据结构：GEE 中的数据分为两种类型：影像（Image）和要素（Feature），分别对应栅格数据和矢量数据。影像和要素可以组成集合（Collection），表示多个影像或要素的堆叠。GEE 中的数据都是以对象（Object）的形式存在，每个对象都有自己的属性（Property）和方法（Method）。\nGEE 的操作方法：GEE 使用 JavaScript 语言编写代码，可以在浏览器中运行。GEE 中的代码分为客户端和服务器端，客户端的代码主要用于控制界面和交互，服务器端的代码主要用于处理数据和分析。GEE 中的数据处理主要依赖于归约器（Reducer），它们可以对影像或要素进行各种统计、分析和转换操作。GEE 还提供了一些高级的功能，如回归、连接、机器学习等。\n\n课程实践练习部分中可以了解到：\n\n高级像素级图像变换：本章介绍了如何在GEE中进行主成分分析（PCA）和缨帽变换（tasselled cap），这些是一种降维和特征提取的方法，可以用于遥感图像的分类和变化检测。\nGEE应用程序和数据目录：GEE还可以创建交互式的可视化应用程序，展示一些有趣和有用的遥感分析案例。GEE还提供了一个庞大的数据目录，包括高分辨率的卫星图像、空气污染物、行政边界等数据集。"
  },
  {
    "objectID": "wk5_GEE.html#whats-gee",
    "href": "wk5_GEE.html#whats-gee",
    "title": "3  Week5 - Google Earth Engine",
    "section": "3.2 What’s GEE",
    "text": "3.2 What’s GEE"
  },
  {
    "objectID": "wk7_classification1.html#overfiting",
    "href": "wk7_classification1.html#overfiting",
    "title": "4  Week7 - Classification-I",
    "section": "4.1 Overfiting",
    "text": "4.1 Overfiting\n\nTree score = SSR + tree penalty (alpha) * T (number of leaves)\n\n对于Tree score公式，为啥去掉越多leaf, alpha越大？\n在决策树的剪枝过程中，我们使用一个参数称为ccp_alpha（cost complexity parameter）来控制剪枝的程度。这个参数的值越大，意味着我们更倾向于剪掉更多的叶节点，从而简化树的结构。\n让我们来理解一下为什么去掉越多的叶节点，ccp_alpha 就越大：\n\n基尼杂质和树的复杂度：\n\n基尼杂质是用来衡量数据集纯度的指标，它越小表示数据集的纯度越高。\n在剪枝过程中，我们希望保留那些对模型性能有积极影响的叶节点，同时减少模型的复杂度。\n当我们去掉一个叶节点时，基尼杂质会增加，因为我们丧失了这个叶节点的纯度。\n\n成本复杂度：\n\nccp_alpha 是一个成本复杂度参数，它在剪枝过程中平衡了模型的拟合程度和复杂度。\n当我们增大 ccp_alpha 时，模型更倾向于剪掉更多的叶节点，从而减少模型的复杂度。\n这样做的目的是防止过拟合，提高模型的泛化能力。\nYoutube video\nHow to Prune Regression Trees"
  },
  {
    "objectID": "wk7_classification1.html#random-forest",
    "href": "wk7_classification1.html#random-forest",
    "title": "4  Week7 - Classification-I",
    "section": "4.2 Random Forest",
    "text": "4.2 Random Forest"
  },
  {
    "objectID": "wk9_SAR_data.html#abstract",
    "href": "wk9_SAR_data.html#abstract",
    "title": "5  Week9 - Synthetic Aperture Radar (SAR) data",
    "section": "5.1 Abstract",
    "text": "5.1 Abstract\nThis class introduces the basic principle of synthetic aperture radar (SAR), two sensor types, SAR data background, SAR data value, SAR polarization, SAR background, differential interferometric synthetic aperture radar (DlnSAR), SAR data processing, SAR data fusion, SAR image fusion and other concepts. This paper also introduces how to use SAR data for change detection, including statistical test, threshold screening and ROC curve, image fusion and so on. Finally, a change detection algorithm based on SAR data is proposed, and an example is given."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "intro.html#summary-of-week-1-class",
    "href": "intro.html#summary-of-week-1-class",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.2 Summary of week 1 class",
    "text": "1.2 Summary of week 1 class\n\n远程感知城市和环境：这是一门介绍远程感知基本原理和应用的课程，主要关注城市和环境问题。\n远程感知的类型和原理：远程感知分为主动和被动两种，根据是否有自身的能源发射器。远程感知数据受到电磁波与大气和地表的相互作用的影响，需要进行校正和处理。\n远程感知数据的格式和分辨率：远程感知数据通常是栅格数据，有不同的存储格式和组织方式。远程感知数据的质量和应用受到空间、光谱、时间和辐射分辨率的制约。"
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.4 Reflection",
    "text": "1.4 Reflection\nThrough the basic knowledge of this class, I inadvertently deepened my understanding of Landsat series satellites from the concepts of electromagnetic wave, multispectral image and hyperspectral image. Landsat provides the longest continuous space record of Earth’s land mass. Its data is essential for us to make informed decisions about the Earth’s resources and environment. It Landsat is more than just a camera circling the globe with an excellent zoom lens. It measures how much light the Earth reflects from the sun. With Landsat, we have access to a variety of useful images that reveal more about the Earth and help us better understand and manage our planet. For example, these images can be used to monitor the effects of natural and human factors such as land cover, climate change, urbanization, drought, fires, changes in biomass, etc. Therefore, the public use of Landsat data makes a lot of sense, and experts, scholars, and enterprise engineers can implement projects according to their needs."
  },
  {
    "objectID": "intro.html#summary-of-this-class",
    "href": "intro.html#summary-of-this-class",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.2 Summary of this class",
    "text": "1.2 Summary of this class\n\nTele-sensing Cities and Environments: This is a course that introduces the basic principles and applications of tele-sensing, with a focus on urban and environmental issues.\nTypes and principles of remote sensing: Remote sensing is divided into active and passive, depending on whether it has its own energy transmitter. Remote sensing data is affected by the interaction of electromagnetic waves with the atmosphere and the surface, and needs to be corrected and processed.\nFormat and resolution of remote sensing data: Remote sensing data is usually raster data and has different storage formats and ways of organizing. The quality and application of remote sensing data are constrained by spatial, spectral, temporal and radiative resolution."
  },
  {
    "objectID": "intro.html#遥感的基本概念与原理",
    "href": "intro.html#遥感的基本概念与原理",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.3 遥感的基本概念与原理",
    "text": "1.3 遥感的基本概念与原理\n\n1.3.1 被动传感器与主动传感器的区别\n两者的区别在于：被动传感器受大气散射的影响，需要在光照条件良好的时候工作，而主动传感器可以穿透云层、火山灰和大气条件，可以在夜间工作。\n我能找到的关于主动传感器的例子是合成孔径雷达（SAR），可以“看穿云层”，并且具有极化特性，可以根据表面的粗糙度、形状、方向、湿度、盐度、密度等反映出不同的电磁波。\n\n\n1.3.2 关于电磁波"
  },
  {
    "objectID": "wk9_SAR_data.html#difference-of-other-sar",
    "href": "wk9_SAR_data.html#difference-of-other-sar",
    "title": "5  Week9 - Synthetic Aperture Radar (SAR) data",
    "section": "5.2 Difference of other SAR",
    "text": "5.2 Difference of other SAR\n\n\n\n\n\n\n\n\n\nSAR\nInSAR\nDInSAR\nPSInSAR\n\n\n\n\nSynthetic Aperture Radar\nInterferometric Synthetic Aperture Radar\nDifferential Interferometric Synthetic Aperture Radar\nPersistent Scatterer Interferometric SAR\n\n\n\nA radar system capable of producing high-resolution images.\nUses a “virtual” antenna length to combine echo signals received from different positions, resulting in higher-resolution radar imaging.\nUsed for surface observations such as land use, topography, and forest cover.\n\n\nAnalyzes surface deformation by exploiting the phase difference between two remote sensing images.\nCalculates the deformation at each pixel on the ground surface between two observations.\nReveals elevation and deformation information.\n\n\nBuilds upon InSAR by using phase differences from multiple remote sensing images to improve deformation measurement accuracy.\nSensitive to deformation, suitable for monitoring ground surface changes due to earthquakes, mining, landslides, etc.\nUtilizes two SAR images and external topographic data to measure subtle surface deformations.\n\n\nModels and analyzes time series data from multiple SAR images to enhance deformation inversion accuracy.\nReveals spatial distribution of surface deformations, widely used for monitoring urban subsidence and infrastructure changes."
  },
  {
    "objectID": "wk9_SAR_data.html#sar数据的应用",
    "href": "wk9_SAR_data.html#sar数据的应用",
    "title": "5  Week9 - Synthetic Aperture Radar (SAR) data",
    "section": "5.3 SAR数据的应用",
    "text": "5.3 SAR数据的应用\n分析两个图像之间的变化（例如比率或对数比率）\nOpen Access Damage Detection Using Sentinel-1 Imagery\nBlast Damage Assessment\n通过以下方式查看随时间变化的差异：\nPixel-Wise T-Test"
  },
  {
    "objectID": "intro.html#basic-concepts-and-principles-of-remote-sensing",
    "href": "intro.html#basic-concepts-and-principles-of-remote-sensing",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.3 Basic concepts and principles of remote sensing",
    "text": "1.3 Basic concepts and principles of remote sensing\n\n1.3.1 The difference between passive and active sensors\nThe difference between the two is that passive sensors are affected by atmospheric scattering and need to work when light conditions are good, while active sensors can penetrate clouds, volcanic ash and atmospheric conditions and can work at night.\n\n\n\nActive remote sensing example\nPassive remote sensing example\n\n\n\n\nFor the untrained eye, it’s just a bunch of black and white pixels. But the reality is that there’s more than meets the eye. For example, the 3 main types of backscatter are: Specular reflection Double-bounce Diffuse scattering\nPassive remote sensing can be very similar to how our eyes interpret the world. But the power of passive remote sensing is to see light in the whole electromagnetic spectrum. For example, this multispectral image can have different band combinations like color infrared.\n\n\nAn example of an active sensor is synthetic Aperture radar (SAR), which can “see through the clouds” and has polarization characteristics that can reflect different electromagnetic waves based on surface roughness, shape, orientation, humidity, salinity, density, etc.\nIn terms of passive remote sensing, the Landsat mission is the longest-running earth observation program. On board Landsat-8, OLI generates 9 spectral bands (Band 1 to 9).\n\n\n\n\na SAR image\n\nRocky Mountains in true color\n\n\n\n\n\n1.3.2 The relation between electromagnetic wave and multispectrum\nAccording to the frequency of electromagnetic wave vibration, the electromagnetic spectrum can be divided into visible spectrum and invisible electromagnetic spectrum two parts.\nMultispectral remote sensing refers to the remote sensing observation and research of ground targets in multiple spectral bands. These bands can include infrared, visible, near-infrared, etc. By analyzing the information of these different bands, more information about the ground target can be obtained.\n{p align=“center” fig-align=“center” width=“424”}\n\n\n\nComparison of spectral bands between Sentinel-2 and Landsat-8(López-Puigdollers, Mateo-García, and Gómez-Chova 2021)\n\n\nIn general, the relationship between electromagnetic wave and multi-spectrum is that multi-spectral remote sensing uses different bands of electromagnetic wave, and more information of ground targets can be obtained by analyzing the information of these bands."
  },
  {
    "objectID": "intro.html#reference",
    "href": "intro.html#reference",
    "title": "1  Week1 - Introduction of RS",
    "section": "1.5 Reference",
    "text": "1.5 Reference\nLópez-Puigdollers D, Mateo-García G, Gómez-Chova L. Benchmarking Deep Learning Models for Cloud Detection in Landsat-8 and Sentinel-2 Images. Remote Sensing. 2021; 13(5):992. https://doi.org/10.3390/rs13050992\n\n\n\n\nLópez-Puigdollers, Dan, Gonzalo Mateo-García, and Luis Gómez-Chova. 2021. “Benchmarking Deep Learning Models for Cloud Detection in Landsat-8 and Sentinel-2 Images.” Remote Sensing 13 (5): 992. https://doi.org/10.3390/rs13050992."
  }
]